
# README for all notebooks

This project contains code for various time series forecasting models. Below are the steps to set up the environment and install the necessary libraries.

## Prerequisites

- Python 3.8 or later
- Jupyter Notebook

## Installation

1. **Clone the repository** (if applicable):
    ```sh
    git clone <repository-url>
    cd <repository-directory>
    ```

2. **Set up a virtual environment** (recommended):
    ```sh
    python3 -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3. **Install the required libraries**:
    ```sh
    pip install pandas matplotlib numpy scikit-learn statsmodels xgboost prophet seaborn random tensorflow ascii_letters pathlib pmdarima math
    ```

## Required Libraries

Here is a list of all the libraries used in the project:

- `pandas`: For data manipulation and analysis.
- `matplotlib`: For plotting and visualization.
- `numpy`: For numerical computations.
- `scikit-learn`: For machine learning algorithms and metrics.
- `statsmodels`: For statistical models and tests.
- `xgboost`: For gradient boosting algorithms.
- `prophet`: For forecasting time series data.
- `seaborn`: For statistical data visualization.
- `random`: For reproducing results.
- `tensorflow`: For machine learning algorithms.
- `ascii_letters`: For exploratory data analysis.
- `pathlib`: For exploratory data analysis.
- `pmdarima`: For multivariate ARIMA modeling.
- `math`: Common math functions.

## Directory Structure

The project directory should be organized as follows:

```
ExploratoryDataAnalysis_complete.ipynb # EDA code
LSTM Submission.ipynb # LSTM Multivariate Models
LSTM Validation.ipynb # LSTM Model for validation
Multivariate_ARIMA.ipynb # ARIMA Multivariate Models
UniVariate Models Complete.ipynb # Univariate Models
README.md            # This README file
Data/
├── training_data.csv                # Training Data
├── validation_data.csv           # Validation Data
└── validation_predictions.csv           # Validation Data with additional column of predicted values (generated by LSTM Validation.ipynb)
```

## Usage

1. **Activate the virtual environment** (if not already activated):
    ```sh
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

2. **Start Jupyter Notebook**:
    ```sh
    jupyter notebook
    ```

3. Open any notebook from the Jupyter interface and run the cells.

## Data

Ensure that you have the required data files in the `Data/` directory before running the notebook. The data files should be organized appropriately to match the paths used in the notebook.

## Results

The results of the analysis, including plots and model outputs, will be stored in the `results/` directory. Ensure that this directory exists or is created during the execution of the notebook.

## Notes

- This project uses the following versions of the libraries (ensure compatibility):
  - pandas >= 1.1.0
  - matplotlib >= 3.1.0
  - numpy >= 1.18.0
  - scikit-learn >= 0.22.0
  - statsmodels >= 0.11.0
  - xgboost >= 1.0.0
  - prophet >= 1.0.1
  - seaborn >= 0.10.0
  - tensorflow >= 2.16.2
  - pathlib >= 1.0.1
  - pmdarima >= 2.0.4
- Ensure you have internet access to download the libraries and dependencies.
- Follow best practices for version control and environment management to maintain project reproducibility.